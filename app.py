import cv2
import mediapipe as mp
import streamlit as st
from img2pose.img2pose import draw_hands
from control.autogui_utils import controller
from PIL import Image
import os
import time
st.set_page_config(layout="wide")
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles

# åœ¨ä¾§è¾¹æ æ·»åŠ é€‰é¡¹
st.sidebar.title("Settings")
confidence = st.sidebar.slider("Confidence", 0.0, 1.0, 0.6)
mode = st.sidebar.selectbox("Control Mode", [0, 1])
scroll_mode = st.sidebar.selectbox("Scroll Mode", [0, 1])
real_resolution_w, real_resolution_h = controller.get_real_resolution()
ctrl_resolution_w, ctrl_resolution_h = controller.get_screen_size()
speed_rate_w = st.sidebar.slider("Speed Rate W", 0, int(real_resolution_w), int(real_resolution_w // 25))
speed_rate_h = st.sidebar.slider("Speed Rate H", 0, int(real_resolution_h), int(real_resolution_h // 25))
scroll_acceleration = st.sidebar.slider("Scroll Acceleration", 1.0, 1.5, 1.1)
enable_audio = st.sidebar.checkbox("Enable Audio")
enable_large_language_model = st.sidebar.checkbox("Enable Large Language Model API")

# æ·»åŠ ç½‘å€è¾“å…¥æ¡†
url = st.sidebar.text_input("URL", "https://github.com/cnsdqd-dyb/-HCI-homework-post-wimp-hand-tracking-interactive-system")

# åˆ›å»ºæ‰‹åŠ¿è¯†åˆ«å¯¹è±¡
hands = mp_hands.Hands(min_detection_confidence=confidence, min_tracking_confidence=confidence)

# æ‰“å¼€æ‘„åƒå¤´
cap = cv2.VideoCapture(0)
ctrl = controller(use_audio=enable_audio, use_llm=enable_large_language_model)
ctrl.scroll_mode = scroll_mode
ctrl.scroll_accelleration = scroll_acceleration
ctrl.speed_rate = [speed_rate_w, speed_rate_h]


col1, col2 = st.columns(2)

with col2:
# åœ¨å³ä¾§æ·»åŠ ä¸€äº›äº¤äº’ç»„ä»¶
    st.title("Interactive Components")

    # æ·»åŠ ä¸€ä¸ªæ»‘å—
    slider = st.slider("Slider", 0, 100, 50)

    # æ·»åŠ ä¸€ä¸ªé€‰æ‹©æ¡†
    selectbox = st.selectbox("Selectbox", ["Option 1", "Option 2", "Option 3"])

    # æ·»åŠ ä¸€ä¸ªå¤é€‰æ¡†
    checkbox = st.checkbox("Checkbox")

    # æ·»åŠ ä¸€ä¸ªè¾“å…¥æ¡†
    text_input = st.text_input("Text Input")

    # æ·»åŠ ä¸€ä¸ªæ—¥æœŸé€‰æ‹©å™¨
    date_input = st.date_input("Date Input")

    # æ·»åŠ ä¸€ä¸ªæ–‡ä»¶ä¸Šä¼ å™¨
    file_uploader = st.file_uploader("File Uploader")

    # æ·»åŠ ä¸€ä¸ªé¢œè‰²é€‰æ‹©å™¨
    color_picker = st.color_picker("Color Picker")

    # æ·»åŠ ä¸€ä¸ªæŒ‰é’®
    button = st.button("Button")

    # æ·»åŠ ä¸€ä¸ªå•é€‰æŒ‰é’®
    radio = st.radio("Radio", ["Option 1", "Option 2", "Option 3"])

    # æ·»åŠ ä¸€ä¸ªæ•°å­—è¾“å…¥æ¡†
    number_input = st.number_input("Number Input")

    # æ·»åŠ ä¸€ä¸ªæ—¶é—´é€‰æ‹©å™¨
    time_input = st.time_input("Time Input")

    # æ·»åŠ ä¸€ä¸ªå¤šè¡Œæ–‡æœ¬è¾“å…¥æ¡†
    text_area = st.text_area("Text Area")

    # æ·»åŠ ä¸€ä¸ªè¿›åº¦æ¡
    progress = st.progress(0)
    for i in range(100):
        progress.progress(i + 1)

with col1:
    st.title("Hand Gesture Recognition")
    # åˆ›å»ºä¸€ä¸ªå ä½ç¬¦ï¼Œæˆ‘ä»¬å°†åœ¨è¿™é‡Œæ˜¾ç¤ºå›¾åƒ
    image_placeholder = st.empty()

    # å¦‚æœå¯ç”¨äº†éŸ³é¢‘ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰éŸ³é¢‘æ–‡ä»¶
    if enable_audio:
        audio_files = [f for f in os.listdir() if f.endswith('.wav') or f.endswith('.mp3')]
        if audio_files:
            selected_audio = st.selectbox("Select an audio file", audio_files)
            st.audio(selected_audio)
        else:
            st.write("No audio files found.")

    # åˆ›å»ºå ä½ç¬¦ä»¥æ˜¾ç¤ºæ§åˆ¶å™¨ä¿¡æ¯
    position_placeholder = st.empty()
    speed_placeholder = st.empty()
    status_placeholder = st.empty()
    time_cost_placeholder = st.empty()

    def get_status_icon(status):
        # å®šä¹‰ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­é”®æ˜¯çŠ¶æ€ï¼Œå€¼æ˜¯å¯¹åº”çš„Unicodeå­—ç¬¦
        status_icons = {
            'scroll up': 'â¬†ï¸',
            'scroll down': 'â¬‡ï¸',
            'scroll left': 'â¬…ï¸',
            'scroll right': 'â¡ï¸',
            'click': 'ğŸ–±ï¸',
            'right click': 'ğŸ–±ï¸',
            'double click': 'ğŸ–±ï¸',
            'drag': 'ğŸ–ï¸',
            'pause': 'â¸ï¸',
            'open': 'ğŸ“‚',
            'screen shot': 'ğŸ“¸',
            'knock': 'ğŸ‘Š',
            'move': 'ğŸš¶',
            'type write': 'âŒ¨ï¸'
        }

        # è¿”å›å½“å‰çŠ¶æ€å¯¹åº”çš„Unicodeå­—ç¬¦ï¼Œå¦‚æœçŠ¶æ€ä¸åœ¨å­—å…¸ä¸­ï¼Œåˆ™è¿”å›ä¸€ä¸ªé»˜è®¤çš„å­—ç¬¦
        return status_icons.get(status, 'â“')

    while cap.isOpened():
        start_time = time.time()

        success, image = cap.read()
        ctrl.hand_screen_width = image.shape[1]
        ctrl.hand_screen_height = image.shape[0]
        if not success:
            print("Ignoring empty camera frame.")
            continue

        image, results = draw_hands(image, hands, mp_hands, mp_drawing, mp_drawing_styles)
            
        ctrl.add_physical_move_track(results, mode=mode)

        # å°†OpenCVå›¾åƒè½¬æ¢ä¸ºPILå›¾åƒï¼Œä»¥ä¾¿Streamlitå¯ä»¥æ˜¾ç¤º
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = Image.fromarray(image)
        
        # åœ¨Streamlitåº”ç”¨ä¸­æ˜¾ç¤ºå›¾åƒ
        image_placeholder.image(image, caption=str(ctrl.current_state), use_column_width=True)

        # æ›´æ–°æ§åˆ¶å™¨ä¿¡æ¯
        position_placeholder.markdown(f"## Control Position: {ctrl.position()}")
        speed_placeholder.text(f"Control Speed: {ctrl.move_speed}")
        status_placeholder.markdown(f"## Control Status: {ctrl.current_state}" + get_status_icon(ctrl.current_state))
        time_cost_placeholder.text(f"Time Cost: {time.time() - start_time}")

        if cv2.waitKey(5) & 0xFF == 27:
            break


hands.close()
cap.release()
